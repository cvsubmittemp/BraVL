{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n# Plot 2D Volume Data\n\nThis plots example volume data onto an example subject, S1, onto a flatmap\nusing quickflat. In order for this to run, you have to have a flatmap for\nthis subject in the pycortex filestore.\n\nThe cortex.Volume2D object is instantiated with two numpy arrays of the same\nsize as the scan for this subject and transform. Here, there are two datasets\nthat have been generated to look like gradients across the brain, but you can\nreplace these with any numpy arrays of the correct dimensionality.\n\nThe colormap used in the first two flatmaps is\n\n<img src=\"file://../../../filestore/colormaps/RdBu_covar.png\">\n\nAs with a 1D Volume, you can change vmin and vmax to threshold, but here\nthey can be manipulated individually for the two arrays.\n\nYou can also change the colormap when creating a new 2D volume.  The colormap\nused in the last flatmap is\n\n<img src=\"file://../../../filestore/colormaps/GreenWhiteBlue_2D.png\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'build/bdist.linux-x86_64/wheel/pycortex-1.2.1.data/data/share/pycortex/db/S1/transforms/fullhead/matrices.xfm'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-6-66349f05912c>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;31m# This creates a 2D Volume object for both of our test datasets for the given\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;31m# subject and transform\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 17\u001B[0;31m \u001B[0mvol_data\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcortex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mVolume2D\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtest_data1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtest_data2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxfm\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     18\u001B[0m \u001B[0mcortex\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mquickshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvol_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mwith_colorbar\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     19\u001B[0m \u001B[0mplt\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshow\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/cortex/dataset/view2D.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, dim1, dim2, subject, xfmname, description, cmap, vmin, vmax, vmin2, vmax2, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdim2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim1\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVolume\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxfmname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmax\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmax\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdim2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mVolume\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mxfmname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmin2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmax\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmax2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/cortex/dataset/views.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, subject, xfmname, mask, cmap, vmin, vmax, description, **kwargs)\u001B[0m\n\u001B[1;32m    271\u001B[0m         super(Volume, self).__init__(data, subject, xfmname, mask=mask, \n\u001B[1;32m    272\u001B[0m                                      \u001B[0mcmap\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mcmap\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmin\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmin\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mvmax\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mvmax\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 273\u001B[0;31m                                      description=description, **kwargs)\n\u001B[0m\u001B[1;32m    274\u001B[0m         \u001B[0;31m# set vmin and vmax\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    275\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvmin\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvmin\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mvmin\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m \u001B[0;32melse\u001B[0m\u001B[0;31m \u001B[0m\u001B[0;31m\\\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/cortex/dataset/braindata.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, data, subject, xfmname, mask, **kwargs)\u001B[0m\n\u001B[1;32m    141\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxfmname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mxfmname\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    142\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 143\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_check_size\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmask\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    144\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmasked\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_masker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    145\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/cortex/dataset/braindata.py\u001B[0m in \u001B[0;36m_check_size\u001B[0;34m(self, mask)\u001B[0m\n\u001B[1;32m    235\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmovie\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    236\u001B[0m                 \u001B[0mshape\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 237\u001B[0;31m             \u001B[0mxfm\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mdb\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_xfm\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mxfmname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    238\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mxfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0mshape\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    239\u001B[0m                 \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Volumetric data (shape %s) is not the same shape as reference for transform (shape %s)\"\u001B[0m \u001B[0;34m%\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxfm\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/tf2/lib/python3.7/site-packages/cortex/database.py\u001B[0m in \u001B[0;36mget_xfm\u001B[0;34m(self, subject, name, xfmtype)\u001B[0m\n\u001B[1;32m    449\u001B[0m         \u001B[0mfname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilestore\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"transforms\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"matrices.xfm\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    450\u001B[0m         \u001B[0mreference\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mos\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpath\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mjoin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfilestore\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0msubject\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"transforms\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"reference.nii.gz\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 451\u001B[0;31m         \u001B[0;32mwith\u001B[0m \u001B[0mopen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfname\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    452\u001B[0m             \u001B[0mxfmdict\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mjson\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mload\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mTransform\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mxfmdict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mxfmtype\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mreference\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'build/bdist.linux-x86_64/wheel/pycortex-1.2.1.data/data/share/pycortex/db/S1/transforms/fullhead/matrices.xfm'"
     ]
    }
   ],
   "source": [
    "import cortex\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nsubject = \"S1\"\nxfm = \"fullhead\"\n\n# Creating two different test datasets that are both the same shape as this\n# transform with one entry for each voxel\n# The matrices have just been reordered in different ways so that they make\n# gradients across the brain in different directions\ntest_data1 = np.arange(31 * 100 * 100).reshape((31, 100, 100), order='C')\ntest_data2 = np.arange(31 * 100 * 100).reshape((31, 100, 100), order='F')\n\n# This creates a 2D Volume object for both of our test datasets for the given\n# subject and transform\nvol_data = cortex.Volume2D(test_data1, test_data2, subject, xfm)\ncortex.quickshow(vol_data, with_colorbar=False)\nplt.show()\n\n# You can alter the minimum and maximum values shown on the colorbar and this\n# can be done separately for the two different datasets\nvol_data = cortex.Volume2D(test_data1, test_data2, subject, xfm,\n                           vmin=np.mean(test_data1), vmax=np.max(test_data1),\n                           vmin2=np.min(test_data2), vmax2=np.mean(test_data2))\ncortex.quickshow(vol_data, with_colorbar=False)\nplt.show()\n\n# To change the colormap, you have to create a new Volume2D object\nvol_color = cortex.Volume2D(test_data1, test_data2, subject, xfm,\n                            cmap=\"GreenWhiteBlue_2D\")\ncortex.quickshow(vol_color, with_colorbar=False)\nplt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-tf2-py",
   "language": "python",
   "display_name": "Python [conda env:tf2] *"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}